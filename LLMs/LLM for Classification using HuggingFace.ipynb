{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83cde373-a766-4778-a803-b8204076db70",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32a282d-149a-474a-ad18-c757a9e3a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd20194-e0f5-4ec5-9e46-a49d2ab6c55f",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b560f0b-8d4b-4859-ae74-ca639ed62e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"twitter_training.csv\", header = None)\n",
    "test_df = pd.read_csv(\"twitter_validation.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d96d02d8-21ba-4ec7-82c5-5d49693dfc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df7888d-ad6e-4d66-ab25-53e149082354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([0, 1], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15e0c75-07b3-4988-a86e-eac85ceab58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Sentiment', 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a42051c-d219-43a3-b561-29c8ae68a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaf67e4-05a5-47ec-906b-8bdae2eda4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0551b363-df5a-4b43-8757-13a3b780ed2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13791</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RhandlerR how does ur cover athletes jumpshot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36962</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>New post: This Microsoft Office exploit was fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56844</th>\n",
       "      <td>Negative</td>\n",
       "      <td>@Ubisoft @Rainbow6Game Okay you tried with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63536</th>\n",
       "      <td>Negative</td>\n",
       "      <td>bruh @ EAMaddenNFL this h2h game's stuck on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70473</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>With the addition of AI Teammates, Auroa feels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14952</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>2.5K Bracket , Ranked after Turbo || !twitch !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44704</th>\n",
       "      <td>Negative</td>\n",
       "      <td>okay is the @Verizon network is ever going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>.:: Ah yes. A very old picture of Demon Lottie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56416</th>\n",
       "      <td>Positive</td>\n",
       "      <td>@Ubisoft @Rainbow6Game I would love that you b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45640</th>\n",
       "      <td>Positive</td>\n",
       "      <td>When you tell on me you don â€™ t actually have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                               Text\n",
       "13791  Negative  RhandlerR how does ur cover athletes jumpshot ...\n",
       "36962   Neutral  New post: This Microsoft Office exploit was fi...\n",
       "56844  Negative  @Ubisoft @Rainbow6Game Okay you tried with the...\n",
       "63536  Negative  bruh @ EAMaddenNFL this h2h game's stuck on th...\n",
       "70473   Neutral  With the addition of AI Teammates, Auroa feels...\n",
       "...         ...                                                ...\n",
       "14952   Neutral  2.5K Bracket , Ranked after Turbo || !twitch !...\n",
       "44704  Negative  okay is the @Verizon network is ever going to ...\n",
       "517     Neutral  .:: Ah yes. A very old picture of Demon Lottie...\n",
       "56416  Positive  @Ubisoft @Rainbow6Game I would love that you b...\n",
       "45640  Positive  When you tell on me you don â€™ t actually have ...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5054ab23-4f94-4c26-83df-a3e7ae408b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Neutral', 'Irrelevant', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97db9307-961d-419d-b981-cadf14eae3be",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f910332-0360-4a08-bc40-5448df639df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ce684a-150a-4483-8cfd-ddb6f810656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a737c-49ee-4571-8ba6-0b0070c18b57",
   "metadata": {},
   "source": [
    "# Converting to Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b7c811a-7924-47ee-a553-ac03fb1d195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a047982d-dc19-4f79-927a-46662659aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Sentiment', 'Text'],\n",
       "    num_rows: 900\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34a4a3-2633-46ac-90d7-f0efd72f926b",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07b7a51-0efa-4389-9240-adaa196a57e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d4e45cc8c044d594a9aca5349ebe8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11237c81bd64a5c83f23b5fc8eed5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c5cbfd72c34c89bafc3cda99fb2781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1a428b9f004d06bf89d2015455d0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadc1583360b4184aaee6913f7831dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cdb70b1282437fba75f4ef55a999dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example['Text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36584f97-7b57-4e43-9d8d-f3046a52c132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9750e4684bb84e71a442ae1ec3643102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e710a7bb0f5412681a36aff7118bf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_dict = {'Positive': 0, 'Negative': 1, 'Neutral': 2, 'Irrelevant': 3}\n",
    "def convert_sentiment_to_label(example):\n",
    "    label = label_dict[example['Sentiment']]\n",
    "    return {'labels': label}\n",
    "\n",
    "train_dataset = train_dataset.map(convert_sentiment_to_label)\n",
    "test_dataset = test_dataset.map(convert_sentiment_to_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76ef0e-4685-465e-ad0f-a582b7673122",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3de3e568-f7d8-4e97-a575-85a02c74e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de334986-da59-48b8-9532-81ea9ed1526a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc47f116-1986-4fc7-9b81-0658a644b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea79c3b3-a805-4223-91a4-b169983e33c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # number of training epochs\n",
    "    per_device_train_batch_size=8,   # batch size for training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bdafa0f9-e618-44ce-a3dc-e57be1c8a35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 00:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.251400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.313200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.165100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.164900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=113, training_loss=1.2014482464410563, metrics={'train_runtime': 48.2454, 'train_samples_per_second': 18.655, 'train_steps_per_second': 2.342, 'total_flos': 236804202086400.0, 'train_loss': 1.2014482464410563, 'epoch': 1.0})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603099f-3b43-43db-ac37-56c53260050d",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8572d9de-df58-4280-baa8-bf47daee3bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2190449237823486,\n",
       " 'eval_accuracy': 0.49,\n",
       " 'eval_f1': 0.4523195295270767,\n",
       " 'eval_precision': 0.4230291005291005,\n",
       " 'eval_recall': 0.49,\n",
       " 'eval_runtime': 2.0754,\n",
       " 'eval_samples_per_second': 48.183,\n",
       " 'eval_steps_per_second': 3.373,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2b67c-66c1-4748-9b72-3016ee3ff2e7",
   "metadata": {},
   "source": [
    "# Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e576ee25-e80b-4287-8ef9-e162fc0e7720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: Positive\n"
     ]
    }
   ],
   "source": [
    "input_text = \"I like this movie\"\n",
    "encoded_input = tokenizer(input_text, return_tensors='pt', truncation=True, max_length=512, padding='max_length').to('cuda')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded_input)\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "predicted_index = predictions.argmax().item()\n",
    "\n",
    "labels = ['Positive', 'Negative', 'Neutral', 'Irrelevant']\n",
    "predicted_label = labels[predicted_index]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d1ec1-30b0-493c-97f9-35ca94ea7311",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9a4cad8-2ab8-43b0-b667-1108894bcc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/tokenizer_config.json',\n",
       " 'model/special_tokens_map.json',\n",
       " 'model/vocab.txt',\n",
       " 'model/added_tokens.json',\n",
       " 'model/tokenizer.json')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('model')\n",
    "tokenizer.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f95117-dd23-4a21-83f8-1fd3f37e4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418a4ba-de53-44f6-ad1b-9a0059dc6b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
